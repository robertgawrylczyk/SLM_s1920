# Laboratory exam SLM 03.06.2020
# Duration: 2h
# Index number: 63913


# Task1(12p)
# In the task, use the data from 'http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric'
# You can load the data using:
read.fwf('http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data-numeric', widths = rep(4, 25), header = FALSE)

# (1p) Rename 25th column to 'target'.It contains information about bank's clients default - 2 => client with a default, 1=> client with no default. Recode 'target' to mark client with default as 1 and 0 otherwise.
# (3p) Check frequencies of 'target' values. How can we cope with unbalanced data? Name at least 3 solutions. Randomly undersample the data to have 50/50 proportions of 'target' values.
# (1p) Divide balanced data into training (85%) and validation (15%) with seed equal to 32
# (1p) Build logistic regression model with 'glm' function. We want to classify 'target' using all other features in a dataset.
# (2p) Conduct feature selection using 'step' function. Use BIC (Bayesian Information Criterion) as model selection criterion. How many variables were removed from model compared to initial logistic regression?
# (4p) Using model after feature selection, conduct cost-based threshold optimization on test data with False Positive cost equal to 2 and False Negative Equal to 5. Plot cost-threshold relation and provide optimal cutoff threshold value.

# Task2(24p)
# Use the data under 'https://archive.ics.uci.edu/ml/machine-learning-databases/00451/dataR2.csv', consisting data of people with breast cancer. If the patient has breast cancer variable Classification is 2, otherwise value 1 is used.
# The values in the data set are separated by a comma, they have headers (read it using function 'read.csv', with the stringsAsFactors parameter equal to FALSE).
# (1p) Check if any data is missing. If so, remove data from the dataset.
# (1p) Recode the variable Classification - ill patients should be denoted as 1 and healthy as 0 - do not create a new variable, but overwrite it
# (2p) By how many years on average (variable Age) people with breast cancer are older/younger than the others?
# (1p) What is the average Insulin level (Insulin variable) for users with a BMI over 22?
# (1p) Randomly divide observations into a training (85% share) and test (15%) set with a seed of 22.
# (2p) Prepare the decision tree from the 'rpart' package based on the data from the training set. The target variable is Classification, use all others to explain it. Set the parameter CP to 0. Remember that rpart infers a task by the type of target variable and we are interested in classification
# (3p) Choose the optimal level of tree complexity, based on CP parameter table produced by rpart. Cut the tree to the optimal size. Explain how to pick the optimal CP level.
# (2p) Draw a pruned decision tree from previous point (with rules).
# (2p) Write one example of decision rule generated by a tree (if ... and ... then we predict than patient is ...)
# (2p) Prepare the confusion matrix for the test set, assuming a cutoff threshold of 0.55
# (3p) Based on the confusion matrix created calculate accuracy, recall and precision. Verify the quality of the tree (subjectively).
# (2p) Draw a Gain curve for the prediction on the test set
# (2p) Calculate AUC for training and test set. Is the model overfitted? Why/Why not? (comment)

# Task3(14p)
# In the task, use the data from 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'
# The quality of white wines is contained in a variable quality.
# The data is separated by a semicolon and has headers. You can load the data using:
read.table('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', stringsAsFactors = F, sep =';', header = T)

# (1p) Check if any data is missing. If so, remove missing data from the dataset.
# (2p) Prepare the histogram and density estimation curve (on the same plot) of the variable volatile.acidity.
# (1p) Divide data into training (90%) and validation (10%) with seed equal to 22
# (3p) Prepare random forest model with library 'randomForest' using default parameter values, with wine quality as target variable and all other variables as predictors. Which 2 explanatory variables explain the most of wine quality variance?
# (3p) Prepare the GAM model with the 'mgcv' package, with wine quality as target variable and all other variables as predictors. Apply smoothing the spline only to 'citric.acid' and 'alcohol' variables
# (2p) Prepare a linear regression model with an 'lm' package, with wine quality as target variable and all other variables as predictors. Provide Adjusted R-squared of the model.
# (2p) Compare the quality of 3 above models by measuring RMSE for each (on test set) and prepare barplot with those values. Which model is the best in terms of RMSE?

